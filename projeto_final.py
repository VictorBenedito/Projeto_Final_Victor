# -*- coding: utf-8 -*-
"""Projeto Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x7WNmfnPnRZgihYdkduv5tmhcQ9TOayd

# 1. Análise de Dados de Expressão Gênica

## Carregamento dos Dados
"""

import pandas as pd

# Carregando os dados
file_path = '/content/drive/MyDrive/expression/expression_file.txt'
df = pd.read_csv(file_path, sep=",")

df.head()

# Normalização dos dados de expressão (z-score)
from sklearn.preprocessing import StandardScaler

# Guardando o dataframe completo
df_complet = df

# Removendo a coluna de diagnóstico
df = df.drop(columns=['diagnostic'])

scaler = StandardScaler()
df_scaled = scaler.fit_transform(df.iloc[:, 1:])  # !!!Primeira coluna é identificador

# Convertendo de volta para DataFrame
df_scaled = pd.DataFrame(df_scaled, columns=df.columns[1:])

# Adicionando a coluna de identificação
df_scaled.insert(0, df.columns[0], df.iloc[:, 0])

df_scaled.head()

"""## Análise Exploratória"""

import matplotlib.pyplot as plt
import seaborn as sns

# Heatmap Correlação
plt.figure(figsize=(12, 10))
sns.heatmap(df_scaled.iloc[:, 1:].corr(), cmap='coolwarm', annot=False)
plt.title('Mapa de Calor das Correlações entre Gênes')
plt.show()

"""## Análise da Expressão Diferencial"""

from scipy.stats import ttest_ind

# Adicionando o diagnóstico
df_scaled['diagnostic'] = df_complet['diagnostic']

# Realizando o teste t
caso = df_scaled[df_scaled['diagnostic'] == 'caso'].iloc[:, 1:-1]
controle = df_scaled[df_scaled['diagnostic'] == 'controle'].iloc[:, 1:-1]

t_stat, p_val = ttest_ind(caso, controle, axis=0)

# Resultados
results = pd.DataFrame({'gene': df.columns[1:], 't_stat': t_stat, 'p_value': p_val})
results['significant'] = results['p_value'] < 0.05

# Exibir os resultados significativos
results_significant = results[results['significant']]
print(results_significant.head(10))

"""# 2. Aplicação de Machine Learning

## Preparação dos Dados
"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Separar características e rótulos
X = df_complet.iloc[:, 1:-1]  # A última coluna é o diagnóstico
y = df_complet['diagnostic']

# Rótulos
y = y.map({'caso': 1, 'controle': 0})

# Dividir os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Normalizar os dados
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""## Treinamento"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score

# Treinar o modelo
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)

# Prever no conjunto de teste
y_pred = model.predict(X_test)

# Avaliar o modelo
print("Confusion Matrix:")
cm = confusion_matrix(y_test, y_pred)
print(cm)

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print("\nAccuracy Score:")
print(accuracy_score(y_test, y_pred))

# Calcular o F1-score
f1 = f1_score(y_test, y_pred, average='weighted')
print("\nF1 Score (weighted):")
print(f1)

# Plotar a matriz de confusão
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Controle', 'Caso'], yticklabels=['Controle', 'Caso'])
plt.xlabel('Predito')
plt.ylabel('Real')
plt.title('Matriz de Confusão')
plt.show()

# Importância das características
importances = model.feature_importances_
features = df_complet.columns[1:-1]

# DataFrame com as importâncias
feature_importances = pd.DataFrame({'gene': features, 'importance': importances})
feature_importances = feature_importances.sort_values(by='importance', ascending=False)

# Genes mais importantes
print(feature_importances.head(10))